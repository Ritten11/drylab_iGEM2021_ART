{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from itertools import chain\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# setting the colorscheme of the figures\n",
    "COLOR = '#307890'\n",
    "mpl.rcParams.update({'text.color' : COLOR,\n",
    "                     'axes.labelcolor' : COLOR,\n",
    "                     'xtick.color': COLOR,\n",
    "                     'ytick.color': COLOR, \n",
    "                     'axes.edgecolor': COLOR})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5becc6bc",
   "metadata": {},
   "source": [
    "# Preprocessing of the data\n",
    "\n",
    "For usage of the ART, it is important that each replicate is assigned a single measurement value which represents how well the replicate performed. This value is often also referred to as the *performance measure*. For our perticular project, we decided to use the activity of the alpha-amylase produces by our machines as the performance measure. However, the output of our experiments is a time-series of absorbance measures and an OD measure for each sample. In this notebook, we go over the steps on how to go from these varying data types to a single alpha-amylase activity value. Note that only one 96 well plate can be processed at the time. If multiple 96 well plates are used, rerun this notebook for each well plate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b81b2a",
   "metadata": {},
   "source": [
    "## Step 1: Loading and structuring the data\n",
    "\n",
    "Before any preprocessing can be done, the measurement data needs to be loaded into the python environment. For easy excess, we will store these measurments in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9e635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the current working directory for later usage\n",
    "cwd = os.getcwd()\n",
    "plate_name = 'AA 2-10' # Change this line in order to analyse a different 96 well plate\n",
    "# Change into the correct working directory\n",
    "data_dir = os.path.join(cwd,'training_data',plate_name)\n",
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d9ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the file names of all absorbance measurement files\n",
    "abs_files = glob.glob('*.TXT')\n",
    "abs_files.sort()\n",
    "print(abs_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66fd4bb",
   "metadata": {},
   "source": [
    "Check wether all the listed files are intended to be used for the analysis. If there are any unwanted files, remove them using the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d10456",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_remove = ['error_2111.TXT'] # More files can be removed by adding more files to this list\n",
    "\n",
    "\n",
    "for file in files_to_remove:\n",
    "    abs_files.remove(file) \n",
    "print(abs_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df456d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Creating a dataframe with time measurements and reference to the absorbance measure file\n",
    "abs_df = pd.DataFrame(columns=['Hour', 'Minute', 'absolute_diff', 'File_name', 'abs_measurements'])\n",
    "for i, file in enumerate(abs_files):\n",
    "    ms_time = file.split('.')\n",
    "    ms_time = [int(string) for string in ms_time[0:2]]\n",
    "    if i == 0:\n",
    "        time_diff = 0\n",
    "    else:\n",
    "        time_diff = (ms_time[0]-abs_df['Hour'][0])*60+(ms_time[1]-abs_df['Minute'][0])\n",
    "    abs_measurement = pd.read_csv(file, header = None, sep=',')\n",
    "    abs_measurement = abs_measurement.iloc[:, :-1] # Due to the output format of the plate reader, there is an extra column with empty values.\n",
    "    abs_df.loc[i] = [ms_time[0], ms_time[1], time_diff, file, abs_measurement]\n",
    "    print(np.shape(abs_df['abs_measurements'][i]))\n",
    "print(abs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c23c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next up, is getting the arrangement of the samples on the plate\n",
    "plate_arr = pd.read_csv('plate_arrangements.csv', sep=',', dtype = str)\n",
    "plate_arr = plate_arr.iloc[:, 1:] # For easy navigation, the first column is removed\n",
    "plate_arr.columns = [int(col_num)-1 for col_num in plate_arr.columns] # The previous step also means that the column names need to be updated\n",
    "\n",
    "# The dataframe of the well locations is now in exactly the same shape as the dataframes used for storing the absorbance measures\n",
    "print(np.shape(plate_arr))\n",
    "\n",
    "print(plate_arr)\n",
    "print(abs_df['abs_measurements'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104774fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the unique values out of the plate arragements\n",
    "samples = plate_arr.values.flatten()\n",
    "samples = np.unique(samples.astype(str)) \n",
    "samples = np.delete(samples, np.where(samples == 'nan'))\n",
    "print(f'Total number of unique samples in dataset: {len(samples)-3}') # Not including the baseline and standard measurements\n",
    "# After extracting the unique values, it is possible to create a disctionary where each sample is matched with the corresponding absorbance measure\n",
    "sample_dict = {}\n",
    "for sample in samples:\n",
    "    coordinates = np.array(np.where(plate_arr == sample)).T\n",
    "    for i, coord in enumerate(coordinates):\n",
    "        sample_name = sample + '_r' + str(i)\n",
    "        sample_dict[sample_name] = [measurement[coord[1]][coord[0]] for measurement in abs_df['abs_measurements']]\n",
    "print(sample_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e87802a",
   "metadata": {},
   "source": [
    "In order to prevent confusion on what the current working directory is, set it back to the original working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b945bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f291d90",
   "metadata": {},
   "source": [
    "## Step 2: Checking the baseline absorbance \n",
    "\n",
    "The data currently stored in sample_dict cannot be used yet. The following data preprocessing steps need to be taken first:\n",
    "\n",
    "1. Check the baseline absorbance and check whether the measured samples need to be accounted for a changing baseline\n",
    "2. Remove any values above the 10nmol standard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483cc8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(abs_df['absolute_diff'], sample_dict['BLANK_r0'])\n",
    "plt.plot(abs_df['absolute_diff'], sample_dict['BLANK_r1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b8c4d",
   "metadata": {},
   "source": [
    "The plot shown above shows the standard of the blank wells. This should show a flat horizontal line. If they are not flat, this would be a possible indication that something went wrong with the measurements. Before moving on, please ensure these curves are in the correct shape, or if they are not, that the unusual shape can be explained. \n",
    "\n",
    "If the blank standard is at it should be, the next step is checking whether there are any datapoints that show an obsorbance which is higher than the 10nmol standard. Measurements above this standard generally no longer increase linearly with respect to time and are thus not represenative of the actual absorbance of the replicate. Measurements of the same replicate taken before the absorbance exceeded the standard can still be used as training data for the ART."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c54285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sample_by_standard(standard, sample, sample_name):\n",
    "    rest = np.subtract(standard, sample)\n",
    "    corrected_sample = sample\n",
    "    for i, d_measurement in enumerate(rest):\n",
    "        if d_measurement < 0:  # If d_measurement is less then 0, it means that absorbance measure in the sample has exceeded the 10 nmol standard\n",
    "            corrected_sample = sample[:i]\n",
    "            print(f'Shortening the time series of sample {sample_name} to length {len(corrected_sample)}')\n",
    "            break\n",
    "    return corrected_sample\n",
    "\n",
    "avg_10nmol_standard = np.average([sample_dict['10nmol_r0'],sample_dict['10nmol_r1']], axis=0)\n",
    "\n",
    "for sample, measurement in sample_dict.items():\n",
    "    if ('#' in sample): # Only check the actual samples and skip the standard and baseline measurements\n",
    "        sample_dict[sample] = correct_sample_by_standard(avg_10nmol_standard, measurement, sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5564d541",
   "metadata": {},
   "source": [
    "## Step 3: Determine alpha-amylase activity of each sample\n",
    "\n",
    "The alpha-amylase activity of a sample is determined by the change in absorbance over time. This change in absorbance is linear with respect to time. Therefore, it is possible to fit a linear curve to each sample in order to abtain a function in the form of $absorbance = a*t+b$, where $a$ is the change in absorbance over time (i.e. the alpha-amylase activity), $t$ is the time and $b$ is some offset. \n",
    "\n",
    "Under perfect conditions, $b$ would be $0$ + the baseline absorbance. However, preparing the samples takes some time. This means that at the time of the first measurement, some samples already had the time to be activated by the reation buffer for about 15 minutes while others were only prepared one minute prior to measurements. This means that $b$ will be higher than the baseline for most of our samples.\n",
    "\n",
    "For our analysis, the exact value of $b$ is irrelevant as the main interest lies within the change in absobance (i.e. $a$). The value of $b$ is only needed in order to fit the linear curve better to the datapoints. Once the curve has been fitted, the $a$ value is used and interpreted as the alpha-amylase activity of the sample. \n",
    "\n",
    "It is however important to first validate wether the absorbance measures indeed follow a linear pattern with respect to time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e7ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining a linear curve\n",
    "def linear_curve(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "# Calculating R^2. For an explanation, see https://stackoverflow.com/questions/19189362/getting-the-r-squared-value-using-curve-fit\n",
    "def determine_R2(xdata, ydata, popt):\n",
    "    residuals = ydata - linear_curve(xdata, *popt)\n",
    "    ss_res = np.sum(residuals**2)\n",
    "    ss_tot = np.sum((ydata-np.mean(ydata))**2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    return r_squared\n",
    "\n",
    "activity_dict={}\n",
    "for sample in sample_dict:\n",
    "    if ('#' in sample): # Only analize the samples and not the standards\n",
    "        ydata = sample_dict[sample]\n",
    "        xdata = abs_df['absolute_diff'][:len(ydata)] # As some samples might have been corrected for exceeding the standard, the length of the xdata might need to be shortened as well for that perticular sample\n",
    "        popt, pcov = curve_fit(linear_curve, xdata, ydata)\n",
    "        a, b = popt\n",
    "        activity_dict[sample] = a # As explaine above, the slope of the curve is anagolous to the activity of the sample\n",
    "        R_squared = determine_R2(xdata, ydata, popt)\n",
    "\n",
    "        # The R^2 value represents how well the y-value can be explained by the x-value by some function f(). In this case,\n",
    "        # the f() function is a first order polynomial (i.e. a linear curve) in the form of f(x)=y=a*x+b. The downside of using \n",
    "        # the R^2 value for representing the fit to a linear curve, is that is there is no slope (i.e. a=0), the R^2 value is 0\n",
    "        # as well. Therefore, all absorbance measures that have a R^2 value of less than 0.95 need to be manually verified on whether\n",
    "        # they are in fact linear curves. \n",
    "        if R_squared < 1: \n",
    "            plt.plot(xdata, ydata, label=sample)\n",
    "            #print(f'R^2 value of sample {sample}: {R_squared}')\n",
    "            print(f'The absorbance measure of sample {sample}:')\n",
    "            print(ydata)\n",
    "        else:\n",
    "            print(f'Sample {sample} fits the linear curve with an R^2 of {R_squared}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e36c5",
   "metadata": {},
   "source": [
    "Based on the figure created in the cell above, it should be possible to locate any replicate that does not show the expected linear behavior. In order to exclude this replicate, along with other replicates of the same sample, enter the name of this sample in the in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e238ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples_to_exclude = ['#21', '#17', '#40', '#43', '#64', '#57'] # for example: ['#26', '#17'] in order to exclude all replicates of samples 26 and 17\n",
    "\n",
    "\n",
    "print(f'Samples in dictionary before removal: {activity_dict.keys()}')\n",
    "for sample in samples_to_exclude:\n",
    "    activity_dict = dict(filter(lambda elem: sample not in elem[0], activity_dict.items()))\n",
    "print(f'Samples in dictionary after removal: {activity_dict.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b04644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(activity_dict) # Printing the raw data in to see the exact values.\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.tick_params(axis='x', rotation=90)\n",
    "ax.set_title('Alpha-amylase activity each replicate',fontsize=20)\n",
    "ax.set_ylabel('Activity (d[Nitrophenol]/dt)', fontsize=15)\n",
    "ax.set_ylim([0,0.006])\n",
    "ax.set_xlabel('Replicate name', fontsize=15)\n",
    "plt.bar(activity_dict.keys(), activity_dict.values(), color='#A40E4C')\n",
    "fig.tight_layout()\n",
    "fig.savefig('./figures/activity_'+plate_name+'.pdf', transparent=True)\n",
    "fig.savefig('./figures/activity_'+plate_name+'.png', transparent=True)\n",
    "# plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da5b63",
   "metadata": {},
   "source": [
    "It is possible that some replicates show a completely different value then the other replicates of the same sample. This absolutely fine. The actual outlier detection is handled by the ART, so these 'weird' values can remain in the input data for the ART."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9d377",
   "metadata": {},
   "source": [
    "## Step 4: Decrease the order of magnitude of the variance within the activity measures\n",
    "\n",
    "Most activity values of the samples that show at least some activity are in between the range of $1*10^{-5}$ and $1*10^{-4}$. While there is already an order of magnitude between these values, some values go as high $6*10^{-3}$. This means that there is a difference of more than two orders of magnitude between the lowest and the highest activity measures. The difference in the lower activity value ranges are therefore close to non-existant in comparison to the total spread of activity values. These differences in lower activity values are however important when training the ART. If most activity measures are considered to be 0, there is not much data to train on. Therefore, a way is needed to project the activity measures which can vary multiple orders of magnitude onto data points which vary only on a single order of magnitude. Taking the natural logarithm is one of the ways of achieving this.\n",
    "\n",
    "\n",
    "A downside of taking the natural logarithm is that values very close to 0 are transformed dispropotionately large negative numbers. However, values close very close to 0 are likely to not show any activity at all. Any variation between these numbers is likely to be caused by a minor measuring error. Therefore, a cutt-off value is needed to prevent the ART from trying to learn these measuring errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f6eff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cut_off = 0.00001\n",
    "\n",
    "for key, value in activity_dict.items():\n",
    "    if value < cut_off:\n",
    "        activity_dict[key] = cut_off\n",
    "\n",
    "zipped_corrected_activities = zip(activity_dict.keys(), np.log(list(activity_dict.values())))\n",
    "corrected_activity_dict = dict(zipped_corrected_activities)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.tick_params(axis='x', rotation=90)\n",
    "ax.set_title('Natual logarithm of Alpha-amylase activity of each replicate',fontsize=20)\n",
    "ax.set_ylabel('Corrected activity (ln(d[Nitrophenol]/dt))', fontsize=15)\n",
    "ax.set_xlabel('Replicate name', fontsize=15)\n",
    "plt.bar(corrected_activity_dict.keys(), corrected_activity_dict.values(), color='#98C9A6')\n",
    "fig.tight_layout()\n",
    "fig.savefig('./figures/ln(activity)_'+plate_name+'.pdf', transparent=True)\n",
    "fig.savefig('./figures/ln(activity)_'+plate_name+'.png', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48085abd",
   "metadata": {},
   "source": [
    "Instead of having values that vary several order of magnitude, all values should now be somewhere between -5 and -12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472eac33",
   "metadata": {},
   "source": [
    "## Step 5: Match the strain name with the strain, promoter, secretion peptide and gene combination and export the results\n",
    "\n",
    "Once the activity of each sample has been determined, this activity needs to be matched to combination of parts used for creating the sample. The end result is a file in which can be directly used by the ART pipeline.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de0d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('sample_list.csv', sep=',') # load in the file contianing the link of the sample name to the various parts\n",
    "\n",
    "for sample in activity_dict:\n",
    "    line_name, replicate = sample.split('_')\n",
    "    print(line_name)\n",
    "    # Adding the measured and corrected activity to the results\n",
    "    results.loc[(results['Line Name']==line_name) & (results['Replicate']==replicate), 'Corrected activity'] = corrected_activity_dict[sample]\n",
    "    results.loc[(results['Line Name']==line_name) & (results['Replicate']==replicate), 'Activity'] = activity_dict[sample]\n",
    "    print(f'Updated entry of line {line_name}')\n",
    "    print(results.loc[(results['Line Name']==line_name) & (results['Replicate']==replicate)])\n",
    "# Write the results into the original file\n",
    "results.to_csv('sample_list.csv', sep=',', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
